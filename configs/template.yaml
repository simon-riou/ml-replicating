# Config specific
device: "cuda"              # <-- device                                  (default: cuda)
num_workers: 8              # <-- number of process for the dataloader    (default: 2)

# Dataset configuration
dataset:                    # MANDATORY                                   (default: Only available in config file not in CLI)
  type: "MNIST"             # MANDATORY Dataset type: "MNIST", "CIFAR10" (TODO), "CIFAR100" (TODO), "ImageFolder" (TODO)
  root: "./data/mnist"      # Root directory for dataset storage
  download: true            # Whether to download the dataset if not present
  
  class_subset: [0, 1, 2]   # List = Keep only class with indices x, y, z | Int = keep X classes | Float = keep x% of classes
  sample_subset: 50        # Int = keep X sample per classes | Float = keep x% of sample per calsses
  download_subset: false    # If true, saves the subset indices to disk cache after creation
  load_subset: false        # If true, loads the subset from disk cache if available (faster)

  # Transform configuration (using Albumentations)
  # Three formats supported:

  # Format 1: Simple preset (recommended for most cases)
  # train_transforms: "cifar10_augmented"
  # test_transforms: "cifar10_basic"

  # Format 2: Preset with overrides
  # train_transforms:
  #   preset: "cifar10_augmented"
  #   override:
  #     normalize:
  #       mean: [0.4914, 0.4822, 0.4465]
  #       std: [0.2470, 0.2435, 0.2616]
  #   additional:
  #     - type: "RandomErasing"
  #       p: 0.2

  # Format 3: Full custom list
  # train_transforms:
  #   - type: "RandomCrop"
  #     height: 32
  #     width: 32
  #     padding: 4
  #   - type: "HorizontalFlip"
  #     p: 0.5
  #   - type: "Normalize"
  #     mean: [0.5, 0.5, 0.5]
  #     std: [0.5, 0.5, 0.5]
  #     max_pixel_value: 255.0
  #   - type: "ToTensorV2"

  # Available presets:
  # - mnist_basic, mnist_augmented
  # - cifar_basic, cifar_augmented (generic CIFAR)
  # - cifar10_basic, cifar10_augmented (CIFAR-10 specific stats)
  # - cifar100_basic, cifar100_augmented (CIFAR-100 specific stats)
  # - imagenet_basic, imagenet_augmented (or imagenet_train/imagenet_test)
  # - food101_basic, food101_augmented
  # - generic_basic, generic_augmented

# Model configuration
model:                      # MANDATORY                                    (default: Only available in config file not in CLI)
  type: "ViT"               # MANDATORY Model type: "ViT", "AlexNet", "MLP", etc ...
  img_size: 224             # Image size (ViT)
  in_channels: 3            # Number of input channels
  patch_size: 16            # Patch size (ViT)
  nb_blocks: 11             # Number of transformer blocks (ViT)
  embed_dim: 768            # Embedding dimension (ViT)
  num_heads: 12             # Number of attention heads (ViT)
  out_classes: 10           # Number of output classes

# Hyperparameters
batch_size: 4096            #                                             (default: 32)
epochs: 90                  #                                             (default: 90)

# Optimizer configuration
optimizer:                  # MANDATORY                                   (default: Only available in config file not in CLI)
  type: "Adam"              # MANDATORY Any parameters available in the doc
  betas: [0.9, 0.999]       # ...
  lr: 0.001                 # ...
  weight_decay: 0.03        # ...

# Criterion (loss function) configuration
criterion:                  # MANDATORY                                   (default: Only available in config file not in CLI)
  type: "CrossEntropyLoss"  # MANDATORY Any parameters available in the doc
  label_smoothing: 0.1      # ...

# Learning rate scheduler configuration
scheduler_list:               # List of schedulers to use with SequentialLR  (default: None)
  - type: "LinearLR"          # First scheduler type
    start_factor: 0.1         # Starting learning rate multiplier
    total_iters: 5            # Number of epochs for this scheduler
  - type: "CosineAnnealingLR" # Second scheduler type
    T_max: 85                 # Maximum number of iterations for cosine annealing
    eta_min: 0.00001          # Minimum learning rate
milestones: [5]               # Epochs at which to switch schedulers

# File save/logs settings
run_dir: "runs/model"       # <-- path to save the model during training  (default: runs/)
tb_dir: "tb-output"         # <-- path to save the tensorboard files      (default: tb-output/)
max_keep: 2                 # <-- max number of model to be saved         (default: 2)